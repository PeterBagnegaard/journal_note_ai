{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bab98801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ToDo Html decode text\n",
    "%run data_lib.ipynb\n",
    "%run plot_lib.ipynb\n",
    "\n",
    "date = '2022-09-01' # Load notater after this date\n",
    "limit = None # Put a limit  on amount of data\n",
    "#model_size = \"bert-base-cased\"\n",
    "model_size = \"bert-base-multilingual-cased\"\n",
    "learning_rate = 2e-05\n",
    "output_dir = \"test3\"\n",
    "#output_dir = f\"{model_size}_learning_rate_{learning_rate}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6246a021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3494/2681091472.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  res = sqlio.read_sql_query(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47349 rows fetched (1.2s)\n",
      "Preprocessing (0.9s)\n",
      "Stripping rich text format (15.4s)\n",
      "Removing 0 of 47349 rows (0.0%) where stripping failed (0.0s)\n",
      "Predicting 155 sks codes (0.0s)\n",
      "Converted sks codes to numpy arrays (0.0s)\n",
      "Removing 2290 of 47349 empty rows (4.8%) (0.3s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagnegaard/anaconda3/lib/python3.10/site-packages/pyarrow/pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['diagnostiknotat_id', 'sks_beskrivelser', 'sks_koder', 'journal_note', 'text', 'labels', '__index_level_0__'],\n",
       "    num_rows: 45059\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, converter = get_diagnostiknotat_data(limit=limit, date=date, sks_count_threshold=100, verbose=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec2b01-b180-4d91-95a4-77d763a40da1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = data.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7c9b3-81cd-430b-a7d3-da9b6b899587",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_size)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "#    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c6d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets['test'] = tokenized_datasets['test'].to_iterable_dataset()\n",
    "tokenized_datasets['train'] = tokenized_datasets['train'].to_iterable_dataset()\n",
    "#small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "#small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c73752-9afb-44f1-bf78-c24eda7f324b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_size, \n",
    "    num_labels=len(dataset[\"train\"]['labels'][0]),\n",
    "#    num_labels=len(tokenized_datasets[\"train\"]['labels'][0]),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d5551-1cb5-43b6-af1d-f80ef2248509",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Your text\n",
    "    text = \"Hello this is a text\"\n",
    "\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Get the model's output\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # The output logits are in the 0th index of outputs\n",
    "    logits = outputs[0]\n",
    "    print(f\"{logits=}\")\n",
    "\n",
    "    # You can get the predicted label using argmax\n",
    "    predicted_label = logits.argmax(dim=1)\n",
    "    print(f\"{predicted_label=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c2e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "def get_trained_model(checkpoint_dir):\n",
    "    file_paths = os.listdir(checkpoint_dir)\n",
    "    numbers = [int(file_path.split('-')[1]) for file_path in file_paths if file_path.startswith('checkpoint')]\n",
    "    last_path = file_paths[np.argmax(numbers)]\n",
    "    print(f\"Getting model {last_path}\")\n",
    "\n",
    "    trained_model = AutoModelForSequenceClassification.from_pretrained(os.path.join(checkpoint_dir, last_path))\n",
    "    trained_model.to('cuda')\n",
    "    return trained_model\n",
    "\n",
    "model = get_trained_model(output_dir)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6e54ea-766f-47b2-a1c4-ba41bb69481c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "#metric = evaluate.load(\"accuracy\")\n",
    "metric = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "#    predictions = np.argmax(logits, axis=-1)\n",
    "#    labels = np.array([np.argmax(val) for val in labels])\n",
    "    predictions = (logits > 0).flatten().astype(float)\n",
    "    labels = labels.flatten().astype(float)\n",
    "    \n",
    "    #print(f\"{labels.shape}\")\n",
    "    #print(f\"{labels=}\")\n",
    "    #print(f\"{predictions.shape}\")\n",
    "    #print(f\"{predictions=}\")\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    report_to='none',\n",
    "    learning_rate = learning_rate,\n",
    "    num_train_epochs = 10,\n",
    "    logging_steps = 100,\n",
    "    max_steps = len(dataset[\"train\"])*2    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "train_out = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f244c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 25\n",
    "plot_prediction(model, tokenized_datasets[\"test\"], idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sum_of_diagnoses ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f9911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sks='BVAA33B'\n",
    "idxs = converter.sks2idx(sks)\n",
    "\n",
    "def filter_func(row):\n",
    "    return (np.array(row['labels']) * idxs).any()\n",
    "    \n",
    "subset = data.filter(filter_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in enumerate(subset):\n",
    "    text = row['text']\n",
    "    truth = np.array(row['labels'], dtype=bool)\n",
    "\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    \n",
    "    input_cuda = {}\n",
    "    for key in inputs.keys():\n",
    "        input_cuda[key] = inputs[key].to('cuda')\n",
    "    \n",
    "    # Get the model's output\n",
    "    outputs = trainer.model(**input_cuda)\n",
    "\n",
    "    # The output logits are in the 0th index of outputs\n",
    "    logits = outputs[0].cpu().detach().numpy().flatten()\n",
    "    x_ax = np.arange(len(truth))\n",
    "    \n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(x=x_ax, y=logits, \n",
    "                         marker_color='black', \n",
    "                         width=0.5, \n",
    "                         name=\"Predicted SKS code\"))\n",
    "\n",
    "    fig.add_trace(go.Bar(x=x_ax[truth], y=logits[truth], \n",
    "                         marker_color='red', \n",
    "                         width=0.5, \n",
    "                         name=\"True SKS code\"))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=x_ax,\n",
    "            ticktext=converter.popular_sks_codes,\n",
    "            tickangle=90\n",
    "        ),\n",
    "        barmode='overlay'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "        \n",
    "    if idx > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1ba28d-a399-4a77-ac28-fab16d4da7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
